{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85540ab0",
   "metadata": {},
   "source": [
    "### 참고문서 \n",
    "테디 랭체인 - https://wikidocs.net/234009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068c511",
   "metadata": {},
   "source": [
    "### 성능 향상을 위한 기본 전략\n",
    "- 리트리버 단계 성능\n",
    "반복적인 *인덱싱 파라미터 튜닝을 하고 리트리버(검색) 성능을 테스트 하여 리트리버 단계의 성능 향상\n",
    "\n",
    "- 답변 생성 단계 성능\n",
    "프롬프트 엔지니어링을 통해 1차적인 성능 향상, 여유가 있다면 질문의 주제를 먼저 판별한뒤 카테고리별로 다른 프롬프트를 통해 최적화된 답변 제공. \n",
    "\n",
    "\n",
    "*인덱싱 : 데이터 불러오고 스플릿, 임베딩, 스토어 적재 까지의 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24065aa",
   "metadata": {},
   "source": [
    "### 추가적인 챗봇 기능\n",
    "- sql 쿼리 참조를 통해 데이터 얻고 답변\n",
    "ex ) 내 보험 만료까지 얼마나 남았어?, 내 문의 처리결과 요약해줘.\n",
    "\n",
    "- 내용 기억하는 챗봇\n",
    "ex ) 보험 내용 알려줘. -> 이전 내용 영어로 번역해줘."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f84f9b",
   "metadata": {},
   "source": [
    "### PDF 청킹 전략\n",
    "- 앞 부분 목차는 날리기: 목차가 영향을 주는 것을 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5b7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "129ea8bc",
   "metadata": {},
   "source": [
    "### 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c40d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "# !python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344efda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LangChain 업데이트\n",
    "# !pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b42914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9faff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d18235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0d9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb1f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56597a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최신 버전으로 업데이트합니다.\n",
    "# !pip install -U langchain langchain_experimental -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e5643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0bb467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bde25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a164552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2bb961",
   "metadata": {},
   "source": [
    "### 임시 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f6918",
   "metadata": {},
   "source": [
    "- OpenAI API Key : https://wikidocs.net/233342\n",
    "- LangSmith 추적 설정 : https://wikidocs.net/250954  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942aa9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c511613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5513301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키 확인\n",
    "import os\n",
    "\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c525bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 디버깅을 위한 프로젝트명을 기입합니다.\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG TUTORIAL\"\n",
    "\n",
    "# tracing 을 위해서는 아래 코드의 주석을 해제하고 실행합니다.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c46dd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000152fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31757f",
   "metadata": {},
   "source": [
    "### 단계 1: 문서 로드(Load Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"./data/202009_5.이동통신단말기분실보험_약관_7.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ecb6ce",
   "metadata": {},
   "source": [
    "pdf 문서 모두다 불러오는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# loader = DirectoryLoader(\".\", glob=\"data/*.pdf\")\n",
    "# docs = loader.load()\n",
    "\n",
    "# print(f\"문서의 수: {len(docs)}\\n\")\n",
    "# print(\"[메타데이터]\\n\")\n",
    "# print(docs[0].metadata)\n",
    "# print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
    "# print(docs[0].page_content[2500:3000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481b4db",
   "metadata": {},
   "source": [
    "### 단계 2: 문서 분할(Split Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfc137f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# PDF 파일을 읽어 텍스트를 추출하는 함수\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# SemanticChunker 설정\n",
    "semantic_text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), add_start_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일에서 텍스트 추출\n",
    "file_path = './data/202009_5.이동통신단말기분실보험_약관_7.pdf'  # PDF 파일 경로\n",
    "text = extract_text_from_pdf(file_path)\n",
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d347bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SemanticChunker를 사용하여 텍스트 스플릿\n",
    "chunks = semantic_text_splitter.split_text(text)\n",
    "\n",
    "# 결과 출력\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d3885",
   "metadata": {},
   "source": [
    "### 3 단계: 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"./data/202009_5.이동통신단말기분실보험_약관_7.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SemanticChunker를 사용하여 텍스트 스플릿\n",
    "splits = semantic_text_splitter.split_documents(docs)\n",
    "\n",
    "# 결과 출력\n",
    "for i, chunk in enumerate(splits):\n",
    "    print(f\"Chunk {i + 1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d1ff4",
   "metadata": {},
   "source": [
    "### 임베딩 모델 고려해서 임베딩 처리\n",
    "기본 값은 text-embeding-ada-002 입니다.  \n",
    "MODEL\tROUGH PAGES PER DOLLAR\tEXAMPLE PERFORMANCE ON MTEB EVAL\n",
    "text-embedding-3-small\t62,500\t62.3%\n",
    "text-embedding-3-large\t9,615\t64.6%\n",
    "text-embedding-ada-002\t12,500\t61.0%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f85236ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 단계 3: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9da0d8",
   "metadata": {},
   "source": [
    "### 4단계: 벡터스토어 생성(Create Vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "987b3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS DB 적용\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a26b1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Chroma DB 적용\n",
    "chroma_vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e024c9",
   "metadata": {},
   "source": [
    "### 5단계: Retriever 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dd009",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"이 보험에서 보상하지 않는 손해는 뭐야?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "print(search_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c80bf",
   "metadata": {},
   "source": [
    "- score_threshold : 유사도 몇 이상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"이 보험에서 보상하지 않는 손해는 뭐야?\"\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
    ")\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "print(search_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f735b",
   "metadata": {},
   "source": [
    "- maximum marginal search result : 문서 몇개 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"이 보험에서 보상하지 않는 손해는 뭐야?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "print(search_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c6f6c",
   "metadata": {},
   "source": [
    "### 다양한 쿼리 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "query = \"이 보험에서 보상하지 않는 손해는 뭐야?\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89ee0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afe7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(query=query)\n",
    "len(unique_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d9c7e",
   "metadata": {},
   "source": [
    "### Ensemble Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a87e7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b815db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"[{i+1}] {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24b33bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BM25 리트리버 설정\n",
    "bm25_retriever = BM25Retriever.from_texts([split.page_content for split in splits])\n",
    "bm25_retriever.k = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e08b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FAISS 벡터스토어 및 리트리버 설정\n",
    "faiss_vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d9fafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 앙상블 리트리버 생성\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06106759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"보험 약관에 대한 설명\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975e1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0f6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0ff4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae676b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427334df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 쿼리로 검색 테스트\n",
    "query = \"보험 약관에 대한 설명\"\n",
    "results = ensemble_retriever.get_relevant_documents(query)\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i + 1}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ae6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = ensemble_retriever.get_relevant_documents(query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2c33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971d387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e03a8e9e",
   "metadata": {},
   "source": [
    "### 6단계: 프롬프트 생성(Create Prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42133655",
   "metadata": {},
   "source": [
    "프롬프트 엔지니어링은 주어진 데이터(context)를 토대로 우리가 원하는 결과를 도출할 때 중요한 역할을 합니다.\n",
    "\n",
    "[TIP1]\n",
    "\n",
    "만약, retriever 에서 도출한 결과에서 중요한 정보가 누락된다면 retriever 의 로직을 수정해야 합니다.\n",
    "만약, retriever 에서 도출한 결과가 많은 정보를 포함하고 있지만, llm 이 그 중에서 중요한 정보를 찾지 못한거나 원하는 형태로 출력하지 않는다면 프롬프트를 수정해야 합니다.  \n",
    "\n",
    "[TIP2]\n",
    "\n",
    "LangSmith 의 hub 에는 검증된 프롬프트가 많이 업로드 되어 있습니다.\n",
    "검증된 프롬프트를 활용하거나 약간 수정한다면 비용과 시간을 절약할 수 있습니다.\n",
    "\n",
    "https://smith.langchain.com/hub/search?q=rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6d92de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652cc53",
   "metadata": {},
   "source": [
    "### 7단계: 언어모델 생성(Create LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff87317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30568961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = model.invoke(\"대한민국의 수도는 어디인가요?\")\n",
    "print(cb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30edd0a",
   "metadata": {},
   "source": [
    "### RAG 템플릿 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbbd2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "# 문서를 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "file_path = \"data/202009_5.이동통신단말기분실보험_약관_7.pdf\"\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# SemanticChunker 설정\n",
    "semantic_text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), add_start_index=True\n",
    ")\n",
    "\n",
    "# SemanticChunker를 사용하여 텍스트 스플릿\n",
    "split_docs = semantic_text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# 단계 3, 4: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=split_docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# 단계 5: 리트리버 생성(Create Retriever)\n",
    "# 사용자의 질문(query) 에 부합하는 문서를 검색합니다.\n",
    "\n",
    "# 유사도 높은 K 개의 문서를 검색합니다.\n",
    "k = 3\n",
    "\n",
    "# (Sparse) bm25 retriever and (Dense) faiss retriever 를 초기화 합니다.\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "bm25_retriever.k = k\n",
    "\n",
    "faiss_vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 단계 7: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 단계 8: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"보상을 받을 수 없는 경우는 언제인가요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"액정이 일부 파손되었어요. 보상 받을 수 있나요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40475dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"식당에서 밥을 먹고 있는데 누가 제 핸드폰을 들고 도망쳤어요. 보상 받을 수 있나요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"특약사항 안에 어떤 보장내용있어?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9fa5f",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ca319",
   "metadata": {},
   "source": [
    "다른 데이터베이스의 URI 형식  \n",
    "- MySQL: mysql+pymysql://username:password@host:port/database \n",
    "- SQL Server: mssql+pyodbc://username:password@host:port/database?driver=ODBC+Driver+17+for+SQL+Server  \n",
    "- Oracle: oracle+cx_oracle://username:password@host:port/database \n",
    "\n",
    "환경에 맞춰 URI 수정하기  \n",
    "위의 형식 중 해당 데이터베이스에 맞는 URI를 사용하되, 사용자명(username), 비밀번호(password), 호스트 주소(host), 포트(port), 데이터베이스 이름(database)을 알맞게 수정하세요. \n",
    "\n",
    "또한, 사용하는 데이터베이스에 따라 필요한 파이썬 패키지를 추가로 설치해야 할 수 있습니다: \n",
    "\n",
    "- PostgreSQL: psycopg2\n",
    "- MySQL: pymysql\n",
    "- SQL Server: pyodbc\n",
    "- Oracle: cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db845f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# PostgreSQL 데이터베이스에 연결합니다.\n",
    "# URI 형식: postgresql://username:password@host:port/database\n",
    "# db = SQLDatabase.from_uri(\"postgresql://testuser:tldl13503tldnfa@172.104.100.7:5432/testdb\")\n",
    "db = SQLDatabase.from_uri(\"postgresql://phone:password@192.168.0.24:5432/phone_care\")\n",
    "\n",
    "# 데이터베이스의 정보를 출력합니다.\n",
    "print(db.dialect)\n",
    "\n",
    "# 사용 가능한 테이블 이름들을 출력합니다.\n",
    "print(db.get_usable_table_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "634263db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 은 gpt-3.5-turbo 를 지정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# LLM 과 DB 를 매개변수로 입력하여 chain 을 생성합니다.\n",
    "chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08e5f9",
   "metadata": {},
   "source": [
    "### 동작하는 코드 메모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e5024ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Unless the user specifies a specific number of examples he wishes to obtain, always limit your query to at most {top_k} results. Only include the executable SQL query in your output, without additional formatting or labels.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "SQL Query to run:\n",
    "SELECT * FROM table_name WHERE condition LIMIT n;\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Here is the description of the columns in the tables:\n",
    "`cust`: customer name\n",
    "`prod`: product name\n",
    "`trans`: transaction date\n",
    "\n",
    "Question: {input}\"\"\"\n",
    ").partial(dialect=db.dialect)\n",
    "\n",
    "# model 은 gpt-3.5-turbo 를 지정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# LLM 과 DB 를 매개변수로 입력하여 chain 을 생성합니다.\n",
    "chain = create_sql_query_chain(llm, db, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e8666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876b4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "39453234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Unless the user specifies in his question a specific number of examples he wishes to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Here is the description of the columns in the tables:\n",
    "`username`: customer name\n",
    "`email`: customer email\n",
    "`model_idx`: customer's phone name\n",
    "\n",
    "Question: {input}\"\"\"\n",
    ").partial(dialect=db.dialect)\n",
    "\n",
    "# model 은 gpt-3.5-turbo 를 지정\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# LLM 과 DB 를 매개변수로 입력하여 chain 을 생성합니다.\n",
    "chain = create_sql_query_chain(llm, db, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591adfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e2dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "bccc2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "당신은 유저로부터 질문을 받아 sql 을 검색해주는 직군입니다. \n",
    "주어진 입력 질문에 따라, 필수 SQL 구문의 {user_pn} 값만 수정해서 {dialect} SQL 쿼리를 완성하세요.\n",
    "내용이 바뀌어선 안됩니다.\n",
    "user_pn의 값은 입력받은 {user_pn} 값만 사용하세요.\n",
    "DB 는 postgresql 입니다.\n",
    "\n",
    "항상 쿼리 결과를 최대 {top_k} 개로 제한하세요.\n",
    "\n",
    "추가적인 서식이나 라벨 없이 이론상으로 실행 가능한 SQL 쿼리만 출력에 포함하세요.\n",
    "\n",
    "다음 테이블만 사용하세요:\n",
    "{table_info}\n",
    "\n",
    "사전 SQL 구문:\n",
    "SELECT *\n",
    "FROM \"User\" AS u\n",
    "JOIN \"Phone_Model\" AS p ON u.model_idx = p.model_idx\n",
    "\n",
    "필수이자 바꿀 SQL 구문:\n",
    "WHERE u.user_pn = {user_pn};\n",
    "\n",
    "\n",
    "\n",
    "다음 형식을 사용하세요:\n",
    "테이블에 있는 컬럼의 설명은 다음과 같습니다:\n",
    "`username`: 고객 이름\n",
    "`email`: 고객 이메일\n",
    "`model_name`: 고객의 휴대폰 모델명, 휴대폰 기종\n",
    "\n",
    "질문: {input}\n",
    "\"\"\"\n",
    ").partial(dialect=db.dialect)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 지정\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# chain 생성\n",
    "chain = create_sql_query_chain(llm, db, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759bd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "generated_sql_query = chain.invoke({\"question\": \"내 폰 기종이 뭐야\", \"user_pn\": \"010-4567-8901\"})\n",
    "\n",
    "# 생성된 쿼리를 출력합니다.\n",
    "print(generated_sql_query.__repr__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "9154448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "# 생성한 쿼리를 실행하기 위한 도구를 생성합니다.\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5efde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query.invoke({\"query\": generated_sql_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "343d4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "# 도구\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "# SQL 쿼리 생성 체인\n",
    "write_query = create_sql_query_chain(llm, db, prompt)\n",
    "\n",
    "# 생성한 쿼리를 실행하기 위한 체인을 생성합니다.\n",
    "chain = write_query | execute_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "a0d2d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과 확인\n",
    "a = chain.invoke({\"question\": \"김철수란 이름의 고객의 이메일을 조회하세요\", \"user_pn\": \"010-4567-8901\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "c76acd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "370a0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과 확인\n",
    "b = chain.invoke({\"question\": \"김철수 폰 기종이 뭐야?\", \"user_pn\": \"010-4567-8901\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "b8834a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('아이폰 SE',)]\""
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fb9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.07/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
